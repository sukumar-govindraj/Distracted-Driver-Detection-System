{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System for Distraction Detection and Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State Farm Distracted Driver Detection has divided driving behavior into 10 classes.Â  \n",
    "\n",
    "\n",
    "| CLASS        | Description          |  \n",
    "| :------------- |:-------------|  \n",
    "| C0     | Safe Driving | \n",
    "| C1     | Texting - Right      |\n",
    "| C2     | Talking On The Phone - Right    |\n",
    "| C3     | Texting- left | \n",
    "| C4     | Talking on the Phone- left | \n",
    "| C5     | Operating The Radio   |\n",
    "| C6     | Drinking| \n",
    "| C7     |  Reaching Behind     |\n",
    "| C8     | Hair And Makeup   |\n",
    "| C9     | Talking To Passenger   |\n",
    "\n",
    "\n",
    "We will implement a deep learning model, which will predict the driver activities at the time of driving. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T21:18:58.416473Z",
     "iopub.status.busy": "2022-07-09T21:18:58.415365Z",
     "iopub.status.idle": "2022-07-09T21:19:04.967476Z",
     "shell.execute_reply": "2022-07-09T21:19:04.96212Z",
     "shell.execute_reply.started": "2022-07-09T21:18:58.416377Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "# image processing\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#keras models\n",
    "from tensorflow.keras import layers ,models,optimizers\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from tensorflow.keras.utils import plot_model\n",
    "#resnet50\n",
    "from tensorflow.keras.applications import resnet50\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input \n",
    "#stop criteria\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "#cnn_visualisation\n",
    "from keras.preprocessing import image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# moving to working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T21:19:04.970415Z",
     "iopub.status.busy": "2022-07-09T21:19:04.969467Z",
     "iopub.status.idle": "2022-07-09T21:20:43.04629Z",
     "shell.execute_reply": "2022-07-09T21:20:43.044826Z",
     "shell.execute_reply.started": "2022-07-09T21:19:04.970373Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!cp -r /kaggle/input/state-farm-distracted-driver-detection/imgs/train ./\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T21:20:43.048935Z",
     "iopub.status.busy": "2022-07-09T21:20:43.048467Z",
     "iopub.status.idle": "2022-07-09T21:20:43.059071Z",
     "shell.execute_reply": "2022-07-09T21:20:43.056362Z",
     "shell.execute_reply.started": "2022-07-09T21:20:43.048882Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dir = \"/kaggle/working/train/\"\n",
    "valid_dir =\"/kaggle/working/val/\"\n",
    "test_dir  = \"/kaggle/working/test/\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# defining classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T21:20:43.063104Z",
     "iopub.status.busy": "2022-07-09T21:20:43.062768Z",
     "iopub.status.idle": "2022-07-09T21:20:43.082472Z",
     "shell.execute_reply": "2022-07-09T21:20:43.08161Z",
     "shell.execute_reply.started": "2022-07-09T21:20:43.063047Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "activity = {   'c0' : \"safe_driving\",\n",
    "                      'c1' : \"texting-right\",\n",
    "                      'c2' : \"talking_on_the_phone-right\",\n",
    "                      'c3' : \"texting-left\",\n",
    "                      'c4' : \"talking_on_the_phone-left\",\n",
    "                      'c5' : \"operating_the_radio\",\n",
    "                      'c6' : \"drinking\",\n",
    "                      'c7' : \"reaching_behind\",\n",
    "                      'c8' : \"hair-and-makeup\",\n",
    "                      'c9' : \"talking_to_passenger\"}\n",
    "activity.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare data\n",
    "**contact each image to its path and label it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T21:20:43.088314Z",
     "iopub.status.busy": "2022-07-09T21:20:43.086645Z",
     "iopub.status.idle": "2022-07-09T21:20:43.09719Z",
     "shell.execute_reply": "2022-07-09T21:20:43.096246Z",
     "shell.execute_reply.started": "2022-07-09T21:20:43.088274Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for file in os.listdir(train_dir):\n",
    "    shutil.move(os.path.join(train_dir,file), os.path.join(train_dir,activity[f'{file}']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T21:20:43.101854Z",
     "iopub.status.busy": "2022-07-09T21:20:43.10065Z",
     "iopub.status.idle": "2022-07-09T21:20:43.452402Z",
     "shell.execute_reply": "2022-07-09T21:20:43.442686Z",
     "shell.execute_reply.started": "2022-07-09T21:20:43.101819Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for file in os.listdir(train_dir):\n",
    "    os.makedirs(valid_dir + '/' + file, exist_ok=True)\n",
    "    os.makedirs(test_dir + '/' + file, exist_ok=True)    \n",
    "    train_dir_img = train_dir + file\n",
    "    file_len = len([sample for sample in os.listdir(train_dir_img)])\n",
    "    print(file_len)   # no of sampels for each class\n",
    "    \n",
    "    for sample in random.sample(os.listdir(train_dir_img) , int(float(0.1) * file_len)):\n",
    "        shutil.move(train_dir_img + '/' + sample, valid_dir + file)# Moving source to newly created destination \n",
    "    for sample in random.sample(os.listdir(train_dir_img) , int(float(0.1) * file_len)):\n",
    "        shutil.move(train_dir_img + '/' + sample, test_dir + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot one image from each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T21:20:43.458771Z",
     "iopub.status.busy": "2022-07-09T21:20:43.456784Z",
     "iopub.status.idle": "2022-07-09T21:20:45.820525Z",
     "shell.execute_reply": "2022-07-09T21:20:45.819486Z",
     "shell.execute_reply.started": "2022-07-09T21:20:43.458726Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 20))\n",
    "image_count = 1\n",
    "BASE_URL = '../input/state-farm-distracted-driver-detection/imgs/train/'\n",
    "for directory in os.listdir(BASE_URL):\n",
    "    if directory[0] != '.':\n",
    "        for i, file in enumerate(os.listdir(BASE_URL + directory)):\n",
    "            if i == 1:\n",
    "                break\n",
    "            else:\n",
    "                fig = plt.subplot(5, 2, image_count)\n",
    "                image_count += 1\n",
    "                image =cv2.imread(BASE_URL + directory + '/' + file)\n",
    "                img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                plt.imshow(img)\n",
    "                plt.title(activity[directory])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **RESIZE IMAGES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageDataGenerator usually used with rescaling factor 1./255 to rescale the initial values from 0 to 255 to 0 to 1 instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T21:20:45.822014Z",
     "iopub.status.busy": "2022-07-09T21:20:45.821666Z",
     "iopub.status.idle": "2022-07-09T21:20:45.828433Z",
     "shell.execute_reply": "2022-07-09T21:20:45.827322Z",
     "shell.execute_reply.started": "2022-07-09T21:20:45.821982Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1 / 255.0)\n",
    "# ImageDataGenerator and usually it is used with rescaling factor 1./255 to rescale the initial values from 0 to 255 to 0 to 1 instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageDataGenerator\n",
    "flow_from_directory (directory), Description:Takes the path to a directory, and generates batches of augmented/normalized data.\n",
    "\n",
    "https://www.datasnips.com/blog/2021/8/30/Image-Augmentation-Using-Keras-ImageDataGenerator-with-Tensorflow/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T21:20:45.830557Z",
     "iopub.status.busy": "2022-07-09T21:20:45.830094Z",
     "iopub.status.idle": "2022-07-09T21:20:46.60399Z",
     "shell.execute_reply": "2022-07-09T21:20:46.602771Z",
     "shell.execute_reply.started": "2022-07-09T21:20:45.830512Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_batches =datagen.flow_from_directory(directory = train_dir,shuffle = True,batch_size = batch_size)\n",
    "val_batches =datagen.flow_from_directory(directory = valid_dir,shuffle = True, batch_size = batch_size)\n",
    "test_batches =datagen.flow_from_directory(directory= test_dir,shuffle = False,batch_size = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T21:20:46.608548Z",
     "iopub.status.busy": "2022-07-09T21:20:46.608229Z",
     "iopub.status.idle": "2022-07-09T21:20:49.312869Z",
     "shell.execute_reply": "2022-07-09T21:20:49.310908Z",
     "shell.execute_reply.started": "2022-07-09T21:20:46.60852Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Flatten(input_shape=(256,256,3)))\n",
    "network.add(layers.Dense(1024,activation = 'relu',name = 'input'))\n",
    "network.add(layers.BatchNormalization())\n",
    "#Batch normalization applies a transformation that maintains the mean \n",
    "#output close to 0 and the output standard deviation close to 1.\n",
    "network.add(layers.Dense(512,activation = 'relu',name = 'l1'))\n",
    "network.add(layers.BatchNormalization())\n",
    "network.add(layers.Dense(256,activation = 'relu',name = 'l2'))\n",
    "network.add(layers.BatchNormalization())\n",
    "network.add(layers.Dense(10,activation = 'softmax',name = 'output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T21:20:49.315771Z",
     "iopub.status.busy": "2022-07-09T21:20:49.314853Z",
     "iopub.status.idle": "2022-07-09T21:20:50.297249Z",
     "shell.execute_reply": "2022-07-09T21:20:50.296097Z",
     "shell.execute_reply.started": "2022-07-09T21:20:49.315725Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_model(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T21:20:50.299865Z",
     "iopub.status.busy": "2022-07-09T21:20:50.299113Z",
     "iopub.status.idle": "2022-07-09T21:20:50.318078Z",
     "shell.execute_reply": "2022-07-09T21:20:50.316932Z",
     "shell.execute_reply.started": "2022-07-09T21:20:50.299824Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "network.compile(optimizer='Adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T21:20:50.320306Z",
     "iopub.status.busy": "2022-07-09T21:20:50.319781Z",
     "iopub.status.idle": "2022-07-09T21:30:14.171227Z",
     "shell.execute_reply": "2022-07-09T21:30:14.170194Z",
     "shell.execute_reply.started": "2022-07-09T21:20:50.320269Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "stop_criteria = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)\n",
    "dense_model=network.fit(x = train_batches,\n",
    "          steps_per_epoch=350,\n",
    "          epochs=15,\n",
    "          validation_data = val_batches,\n",
    "          validation_steps= 50\n",
    "          , callbacks=[stop_criteria]\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T21:30:14.17358Z",
     "iopub.status.busy": "2022-07-09T21:30:14.172892Z",
     "iopub.status.idle": "2022-07-09T21:30:25.020092Z",
     "shell.execute_reply": "2022-07-09T21:30:25.019076Z",
     "shell.execute_reply.started": "2022-07-09T21:30:14.17354Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.plot(dense_model.history['acc'])  # blue line\n",
    "plt.plot(dense_model.history['val_acc']) #orange line\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T21:36:21.351526Z",
     "iopub.status.busy": "2022-07-09T21:36:21.350931Z",
     "iopub.status.idle": "2022-07-09T21:36:41.869324Z",
     "shell.execute_reply": "2022-07-09T21:36:41.868275Z",
     "shell.execute_reply.started": "2022-07-09T21:36:21.351489Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dense_scores= network.evaluate(test_batches)\n",
    "print(\"Accuracy: %.2f%%\" % (dense_scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T21:39:06.583952Z",
     "iopub.status.busy": "2022-07-09T21:39:06.583011Z",
     "iopub.status.idle": "2022-07-09T21:39:06.589956Z",
     "shell.execute_reply": "2022-07-09T21:39:06.588703Z",
     "shell.execute_reply.started": "2022-07-09T21:39:06.583916Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator( rescale=1 / 255.0,\n",
    "                                    zoom_range=0.05,\n",
    "                                    width_shift_range=0.05,\n",
    "                                    height_shift_range=0.05,\n",
    "                                    shear_range=0.05,\n",
    "                                    fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN WITH DATA Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T21:39:07.781759Z",
     "iopub.status.busy": "2022-07-09T21:39:07.781422Z",
     "iopub.status.idle": "2022-07-09T21:39:07.980561Z",
     "shell.execute_reply": "2022-07-09T21:39:07.979606Z",
     "shell.execute_reply.started": "2022-07-09T21:39:07.781731Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cnn_model = models.Sequential()\n",
    "cnn_model.add(layers.Conv2D(32,(3,3),activation = 'relu',name = 'Conv_',input_shape = (256,256,3)))\n",
    "cnn_model.add(layers.Conv2D(32,(3,3),activation = 'relu',name = 'Conv_2',padding = 'same'))\n",
    "cnn_model.add(layers.Conv2D(32,(3,3),activation = 'relu',name = 'Conv_3',padding = 'same'))\n",
    "cnn_model.add(layers.BatchNormalization())\n",
    "cnn_model.add(layers.MaxPooling2D((2,2),name = 'max_1'))\n",
    "cnn_model.add(layers.Conv2D(64,(3,3),activation = 'relu',name = 'Conv_4',padding='same'))\n",
    "cnn_model.add(layers.Conv2D(64,(3,3),activation = 'relu',name = 'Conv_5',padding='same'))\n",
    "cnn_model.add(layers.BatchNormalization())\n",
    "cnn_model.add(layers.MaxPooling2D((2,2),name = 'max_2'))\n",
    "\n",
    "cnn_model.add(layers.Conv2D(128,(3,3),activation='relu'))\n",
    "cnn_model.add(layers.BatchNormalization())\n",
    "cnn_model.add(layers.MaxPooling2D((2,2)))\n",
    "cnn_model.add(layers.Conv2D(128,(3,3),activation='relu'))\n",
    "cnn_model.add(layers.BatchNormalization())\n",
    "cnn_model.add(layers.Flatten())\n",
    "cnn_model.add(layers.Dense(512,activation = 'relu',name = 'L1',))\n",
    "cnn_model.add(layers.BatchNormalization())\n",
    "cnn_model.add(layers.Dense(256,activation = 'relu',name = 'L2'))\n",
    "cnn_model.add(layers.BatchNormalization())\n",
    "cnn_model.add(layers.Dense(256,activation = 'relu',name = 'L3'))\n",
    "cnn_model.add(layers.BatchNormalization())\n",
    "cnn_model.add(layers.Dense(128,activation = 'relu' ,name ='L4'))\n",
    "cnn_model.add(layers.BatchNormalization())\n",
    "cnn_model.add(layers.Dense(10,activation = 'softmax',name = 'output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T21:39:08.278138Z",
     "iopub.status.busy": "2022-07-09T21:39:08.277783Z",
     "iopub.status.idle": "2022-07-09T21:39:08.552475Z",
     "shell.execute_reply": "2022-07-09T21:39:08.551411Z",
     "shell.execute_reply.started": "2022-07-09T21:39:08.278107Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_model(cnn_model,\"model.png\",show_shapes=True,show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T21:39:08.706395Z",
     "iopub.status.busy": "2022-07-09T21:39:08.705528Z",
     "iopub.status.idle": "2022-07-09T21:39:08.720937Z",
     "shell.execute_reply": "2022-07-09T21:39:08.719964Z",
     "shell.execute_reply.started": "2022-07-09T21:39:08.706351Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cnn_model.compile(optimizer = 'adam' , loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T21:39:11.807348Z",
     "iopub.status.busy": "2022-07-09T21:39:11.806659Z",
     "iopub.status.idle": "2022-07-09T21:51:18.400995Z",
     "shell.execute_reply": "2022-07-09T21:51:18.400104Z",
     "shell.execute_reply.started": "2022-07-09T21:39:11.807301Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "stop_criteria = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)\n",
    "cnn_model_history = cnn_model.fit(x = train_batches,\n",
    "          steps_per_epoch=250,\n",
    "          epochs=15,\n",
    "          validation_data = val_batches,\n",
    "          validation_steps= 50,\n",
    "          callbacks=[stop_criteria])\n",
    "\n",
    "# None of the MLIR Optimization Passes are enabled is a bit misleading as it refers to very particular workflow. \n",
    "# But it is benign and has no effect - it just means a user didnât opt in to a specific pass (which is not enabled by default), \n",
    "# so it doesnât indicate any error and was rather used as signal for developers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T21:51:18.404165Z",
     "iopub.status.busy": "2022-07-09T21:51:18.403811Z",
     "iopub.status.idle": "2022-07-09T21:51:18.778566Z",
     "shell.execute_reply": "2022-07-09T21:51:18.777562Z",
     "shell.execute_reply.started": "2022-07-09T21:51:18.404138Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "acc = cnn_model_history.history['acc']\n",
    "val_acc = cnn_model_history.history['val_acc']\n",
    "\n",
    "loss = cnn_model_history.history['loss']\n",
    "val_loss = cnn_model_history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b' ,label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T21:51:18.781901Z",
     "iopub.status.busy": "2022-07-09T21:51:18.780908Z",
     "iopub.status.idle": "2022-07-09T21:51:36.05731Z",
     "shell.execute_reply": "2022-07-09T21:51:36.056107Z",
     "shell.execute_reply.started": "2022-07-09T21:51:18.781862Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cnn_scores = cnn_model.evaluate(test_batches)\n",
    "print(\"Accuracy: %.2f%%\" % (cnn_scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning with resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T21:51:36.060831Z",
     "iopub.status.busy": "2022-07-09T21:51:36.060167Z",
     "iopub.status.idle": "2022-07-09T21:51:36.069812Z",
     "shell.execute_reply": "2022-07-09T21:51:36.068766Z",
     "shell.execute_reply.started": "2022-07-09T21:51:36.060781Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function= resnet50.preprocess_input,\n",
    "                                                zoom_range=0.05,\n",
    "                                                width_shift_range=0.05,\n",
    "                                                height_shift_range=0.05,\n",
    "                                                shear_range=0.05,\n",
    "                                                fill_mode=\"nearest\")\n",
    "\n",
    "resnet_datagen = ImageDataGenerator(preprocessing_function= resnet50.preprocess_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN WITH RESNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T21:51:36.071981Z",
     "iopub.status.busy": "2022-07-09T21:51:36.071703Z",
     "iopub.status.idle": "2022-07-09T21:51:38.554965Z",
     "shell.execute_reply": "2022-07-09T21:51:38.55402Z",
     "shell.execute_reply.started": "2022-07-09T21:51:36.071955Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "conv_model = resnet50.ResNet50(weights='imagenet',include_top=False,input_shape = (256,256,3))\n",
    "\n",
    "for layer in conv_model.layers[:-3]:\n",
    "    layer.trainable=False  #The role of the embedding layer is to map a category into a dense space in a way that is useful for the task\n",
    "\n",
    "resnet_model = models.Sequential()\n",
    "resnet_model.add(conv_model)\n",
    "resnet_model.add(layers.Flatten())\n",
    "\n",
    "cnn_model.add(layers.Dense(512,activation = 'relu',))\n",
    "cnn_model.add(layers.BatchNormalization())\n",
    "\n",
    "resnet_model.add(layers.Dense(256,activation = 'relu'))\n",
    "cnn_model.add(layers.BatchNormalization())\n",
    "\n",
    "resnet_model.add(layers.Dense(128,activation = 'relu'))\n",
    "cnn_model.add(layers.BatchNormalization())\n",
    "\n",
    "resnet_model.add(layers.Dense(10,activation = 'softmax',name = 'output'))  # MULTICLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T21:51:38.557051Z",
     "iopub.status.busy": "2022-07-09T21:51:38.556638Z",
     "iopub.status.idle": "2022-07-09T21:51:38.721323Z",
     "shell.execute_reply": "2022-07-09T21:51:38.720039Z",
     "shell.execute_reply.started": "2022-07-09T21:51:38.556993Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_model(resnet_model,\"model.png\",show_shapes=True,show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T21:51:38.724073Z",
     "iopub.status.busy": "2022-07-09T21:51:38.723147Z",
     "iopub.status.idle": "2022-07-09T21:51:38.743335Z",
     "shell.execute_reply": "2022-07-09T21:51:38.742108Z",
     "shell.execute_reply.started": "2022-07-09T21:51:38.724015Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "resnet_model.compile(optimizer = optimizers.Adam(learning_rate=.0001) ,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T21:51:38.744849Z",
     "iopub.status.busy": "2022-07-09T21:51:38.744511Z",
     "iopub.status.idle": "2022-07-09T22:10:07.656559Z",
     "shell.execute_reply": "2022-07-09T22:10:07.655577Z",
     "shell.execute_reply.started": "2022-07-09T21:51:38.744814Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "stop_criteria = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)\n",
    "resnet_model_history = resnet_model.fit(x = train_batches,\n",
    "          steps_per_epoch=250,\n",
    "          epochs=15,\n",
    "          validation_data = val_batches,\n",
    "          validation_steps= 50,\n",
    "          callbacks=[stop_criteria])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T22:10:07.659142Z",
     "iopub.status.busy": "2022-07-09T22:10:07.658685Z",
     "iopub.status.idle": "2022-07-09T22:10:08.051939Z",
     "shell.execute_reply": "2022-07-09T22:10:08.050995Z",
     "shell.execute_reply.started": "2022-07-09T22:10:07.659102Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "acc = resnet_model_history.history['acc']\n",
    "val_acc = resnet_model_history.history['val_acc']\n",
    "\n",
    "loss = resnet_model_history.history['loss']\n",
    "val_loss = resnet_model_history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b' ,label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T22:10:08.055866Z",
     "iopub.status.busy": "2022-07-09T22:10:08.055598Z",
     "iopub.status.idle": "2022-07-09T22:10:44.053864Z",
     "shell.execute_reply": "2022-07-09T22:10:44.052858Z",
     "shell.execute_reply.started": "2022-07-09T22:10:08.055841Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "resnet_scores= resnet_model.evaluate(test_batches)\n",
    "print(\"Accuracy: %.2f%%\" % (resnet_scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T22:10:44.055827Z",
     "iopub.status.busy": "2022-07-09T22:10:44.055364Z",
     "iopub.status.idle": "2022-07-09T22:10:44.40761Z",
     "shell.execute_reply": "2022-07-09T22:10:44.406644Z",
     "shell.execute_reply.started": "2022-07-09T22:10:44.055789Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Pre-processing the image\n",
    "images, labels  = next(train_batches)\n",
    "img_tensor = images[1]\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "\n",
    "# Print image tensor shape\n",
    "print(img_tensor.shape)\n",
    "\n",
    "# Print image\n",
    "plt.imshow(img_tensor[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T22:10:44.409649Z",
     "iopub.status.busy": "2022-07-09T22:10:44.409075Z",
     "iopub.status.idle": "2022-07-09T22:10:44.644869Z",
     "shell.execute_reply": "2022-07-09T22:10:44.643818Z",
     "shell.execute_reply.started": "2022-07-09T22:10:44.409613Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "layer_outputs = [layer.output for layer in cnn_model.layers[:10]]\n",
    "activation_model = models.Model(inputs=cnn_model.input, outputs=layer_outputs)\n",
    "activations = activation_model.predict(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T22:10:44.646869Z",
     "iopub.status.busy": "2022-07-09T22:10:44.646507Z",
     "iopub.status.idle": "2022-07-09T22:10:46.661529Z",
     "shell.execute_reply": "2022-07-09T22:10:46.655732Z",
     "shell.execute_reply.started": "2022-07-09T22:10:44.646831Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "layer_names = []\n",
    "for layer in resnet_model.layers[:10]:\n",
    "    layer_names.append(layer.name)\n",
    "\n",
    "images_per_row = 16\n",
    "\n",
    "# Now let's display our feature maps\n",
    "for layer_name, layer_activation in zip(layer_names, activations):\n",
    "    # This is the number of features in the feature map\n",
    "    n_features = layer_activation.shape[-1]\n",
    "\n",
    "    # The feature map has shape (1, size, size, n_features)\n",
    "    size = layer_activation.shape[1]\n",
    "\n",
    "    # We will tile the activation channels in this matrix\n",
    "    n_cols = n_features // images_per_row\n",
    "    display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "\n",
    "    # We'll tile each filter into this big horizontal grid\n",
    "    for col in range(n_cols):\n",
    "        for row in range(images_per_row):\n",
    "            channel_image = layer_activation[0,\n",
    "                                             :, :,\n",
    "                                             col * images_per_row + row]\n",
    "            # Post-process the feature to make it visually palatable\n",
    "            channel_image -= channel_image.mean()\n",
    "            channel_image /= channel_image.std()\n",
    "            channel_image *= 64\n",
    "            channel_image += 128\n",
    "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "            display_grid[col * size : (col + 1) * size,\n",
    "                         row * size : (row + 1) * size] = channel_image\n",
    "\n",
    "    # Display the grid\n",
    "    scale = 1. / size\n",
    "    plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                        scale * display_grid.shape[0]))\n",
    "    plt.title(layer_name)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACCURACY OF MODELS USED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# models evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T22:10:46.669353Z",
     "iopub.status.busy": "2022-07-09T22:10:46.666987Z",
     "iopub.status.idle": "2022-07-09T22:10:46.679758Z",
     "shell.execute_reply": "2022-07-09T22:10:46.678703Z",
     "shell.execute_reply.started": "2022-07-09T22:10:46.669315Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# dense_scores\n",
    "acc1=dense_model.history['acc'][-1]\n",
    "vacc1=dense_model.history['val_acc'][-1]\n",
    "# cnn_scores\n",
    "acc2=cnn_model_history.history['acc'][-1]\n",
    "vacc2=cnn_model_history.history['val_acc'][-1]\n",
    "# resnet_scores\n",
    "acc3=resnet_model_history.history['acc'][-1]\n",
    "vacc3=resnet_model_history.history['val_acc'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T22:10:46.684937Z",
     "iopub.status.busy": "2022-07-09T22:10:46.684604Z",
     "iopub.status.idle": "2022-07-09T22:10:46.811395Z",
     "shell.execute_reply": "2022-07-09T22:10:46.81027Z",
     "shell.execute_reply.started": "2022-07-09T22:10:46.684904Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame([[\"DENSE model\",acc1,vacc1,dense_scores[1]*100],\n",
    "                       [\"CNN_data_augmentation\",acc2,vacc2,cnn_scores[1]*100],\n",
    "                       [\"CNN_RESNET model\",acc3,vacc3,resnet_scores[1]*100]],\n",
    "                       columns = [\"Model\",\"Training Accuracy %\",\"Validation Accuracy %\",\"Test Evaluation %\"]).sort_values(by=\"Test Evaluation %\",ascending=False)\n",
    "results.style.background_gradient(cmap='BuPu')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
